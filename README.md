# ğŸ¤ Speech-to-Text Web Application (Internship Project)

A full-stack **Speech-to-Text Web Application** developed as part of an internship project.  
This application allows users to **authenticate**, **upload audio files**, and **convert speech into text** using **Offline Whisper** and **Online OpenAI Whisper**, with transcription history stored securely in **MongoDB Atlas (Cloud)**.

---

## ğŸš€ Quick Overview

| Aspect | Technology |
|------|-----------|
| Frontend | React + Vite |
| Backend | Node.js + Express.js |
| Database | MongoDB Atlas (Online) |
| Authentication | Supabase Email OTP |
| Speech-to-Text (Offline) | OpenAI Whisper (Python) |
| Speech-to-Text (Online) | OpenAI Whisper API |
| File Upload | Multer |
| Version Control | Git & GitHub |

---

## ğŸ§° Technology Stack

### Frontend
- React (Hooks-based)
- Vite (Fast dev server)
- CSS (Custom styling)
- Supabase JS SDK (Authentication)
- Fetch API (Backend communication)

---

### Backend
- Node.js
- Express.js
- Multer (Audio upload handling)
- Mongoose (MongoDB ODM)
- dotenv (Environment variables)
- child_process (`exec`) for offline Whisper
- CORS (Cross-Origin requests)

---

### Database (MongoDB Atlas â€“ Cloud)

#### Audio Schema
```js
{
  filename: String,
  filepath: String,
  transcription: String,
  userId: String,
  createdAt: Date,
  updatedAt: Date
}
ğŸ“ Project Structure
Frontend (/fronted)

src/
â”œâ”€â”€ App.jsx                # Main application logic
â”œâ”€â”€ Auth.jsx               # Authentication UI (Supabase)
â”œâ”€â”€ supabaseClient.js      # Supabase configuration
â”œâ”€â”€ main.jsx               # React entry point
â””â”€â”€ styles.css             # UI styling

Backend (/backend)

models/
â”œâ”€â”€ Audio.js               # MongoDB schema

uploads/
â”œâ”€â”€ *.mp3 / *.wav          # Uploaded audio files

index.js                   # Express server
transcribe.py              # Offline Whisper transcription
whisper.js                 # OpenAI Whisper (Online)
.env                       # Environment variables

âœ¨ Key Features

âœ… Email OTP Authentication (Supabase)
âœ… Audio upload (MP3 / WAV)
âœ… Offline Speech-to-Text using Whisper
âœ… Online Speech-to-Text using OpenAI API
âœ… User-specific transcription history
âœ… MongoDB Atlas cloud database
âœ… Error handling & validation
âœ… Secure environment configuration

ğŸ” Environment Variables

Backend (.env)

PORT=5000
MONGO_URI=mongodb+srv://<username>:<password>@cluster.mongodb.net/speechToText
OPENAI_API_KEY=your_openai_api_key

Frontend (.env)

VITE_SUPABASE_URL=https://your-project.supabase.co
VITE_SUPABASE_ANON_KEY=your_anon_key


Online Whisper (OpenAI)

Uses OpenAI Whisper API

Faster & scalable

Requires API key

Suitable for production

ğŸ›  Implementation Timeline
Day	Work Done
Day 1	Project setup & planning
Day 2	Backend setup (Express, MongoDB)
Day 3	File upload with Multer
Day 4	Offline Whisper integration
Day 5	MongoDB data storage
Day 6	React frontend
Day 7	Audio upload UI
Day 8	Supabase authentication
Day 9	User-based history
Day 10	Error handling
Day 11	Debugging & fixes
Day 12	Integration testing
Day 13	UI polish
Day 14	Documentation


ğŸ§© Challenges Solved

Whisper file path errors (ENOENT)

React invalid hook call issues

Multer upload validation

Supabase email OTP delays

MongoDB Atlas connection issues

CORS & network errors

ğŸ“š Skills & Learnings
Full-Stack Development

Client-server architecture

REST API development

Authentication flows

Backend

Express middleware

MongoDB Atlas integration

File handling with Multer

Offline ML integration

Frontend

React hooks (useState, useEffect)

Conditional rendering

API handling

DevOps & Tools

Git & GitHub

Environment variable management

Debugging production issues

ğŸ“Š Project Statistics

Development Duration: 14 Days

Backend APIs: 5+

React Components: 6+

Technologies Used: 10+

Database: MongoDB Atlas

